---
title: "MA Thesis Code Checks"
author: "Kyle Dewsnap"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: yes
fontsize: 12pt
geometry: margin=1in
---

```{r setup, include=FALSE}
library(tidyverse)
```

As the algorithm that implements the OLS estimator is manually coded, it is wise to check the output of this algorithm against both a worked example and against other, audited statistics software.

## Validation against Worked Example

Let:

- $X$ be an $n * k$ design matrix, where $n$ is the number of observations and $k$ is the number of predictor variables _plus_ one intercept term (the leftmost column of $X$ is filled with ones);
- $\beta$ be a vector of length $k$ representing the true model parameters, and $\hat{\beta}$ be its estimates;
- $\epsilon$ be a vector of length $n$ representing the error terms of the observations, where $\epsilon \sim N(0, \sigma^2)$, and;
- $y$ be a vector of length $n$ representing the actual values of the response variable, and $\hat{y}$ be its estimates from the model.

For this example, we set $n = 4$ and $k = 3$ (namely, we have two predictor variables, $X_1$ and $X_2$). Both predictor variables follow a random distribution: $X_1 \sim N(0, 1), X_2 \sim N(1, 1)$.
$$
X = \left(\begin{array}{ccc}
1 & 0.7 & 2.0 \\
1 & -1.0 & 0.4 \\
1 & 0.7 & 1.5 \\
1 & 0.6 & 0.3 \end{array}\right)\
$$
The true model used to generate the response variable is
$$
\begin{equation}
\begin{split}
Y & = X\beta + \epsilon \\
& = X \left(\begin{array}{c}0.5 \\ 1 \\ -0.5 \end{array}\right)\ + \left(\begin{array}{c}0.2 \\ 1.8 \\ -1.1 \\ 0.0 \end{array}\right)\ \\
& = \left(\begin{array}{c}0.4 \\ 1.1 \\ -0.6 \\ 1.0 \end{array}\right)\
\end{split}
\end{equation}
$$
The OLS estimator of $\beta$ is $\hat{\beta} = (X'X)^{-1}X'y$, where $'$ is the transpose operator. Given our data, the parameter estimates of this model are:
$$
\begin{equation}
\begin{split}
\hat{\beta} & = (X'X)^{-1}X'y \\
 & = \left(\begin{array}{ccc}
4.00	& 1.00 &	4.20 \\
1.00 &	2.34 & 2.23 \\
4.20 & 2.23 & 6.50 \end{array}\right)^{-1}
\left(\begin{array}{cccc}
1 & 1 & 1 & 1 \\
0.7 & -1 & 0.7 & 0.6 \\
2 & 0.4 & 1.5 & 0.3 \end{array}\right)
\left(\begin{array}{c}0.4 \\ 1.1 \\ -0.6 \\ 1.0 \end{array}\right)\ \\
 & = \left(\begin{array}{ccc}
0.860 & 0.241 & -0.638 \\
0.241 & 0.702 & -0.397 \\
-0.638 & -0.397 & -0.702
 \end{array}\right)
 \left(\begin{array}{c}1.90 \\ -0.64 \\ 0.64 \end{array}\right)\ \\
 & = \left(\begin{array}{c}1.071 \\ -0.246 \\ -0.510 \end{array}\right)\
\end{split}
\end{equation}
$$
This test was passed; see `LmOLS_Test.cpp:26-28'.

The standard errors of $\hat{\beta}$ are given by the squared diagonal of the variance-covariance matrix of the OLS estimates. This is given by
$E[(\hat{\beta} - \beta)(\hat{\beta} - \beta)'] = \hat{\sigma^2}(X'X)^(-1)$, where $\hat{\sigma^2} = \frac{RSS}{n - k}$. Given our data, the standard errors of the parameter estimates of this model are:
$$
\begin{equation}
\begin{split}
\hat{\sigma}^2 & = \frac{RSS}{n - k} \\
 & = \frac{\sum_{i=0}^n\hat{y}_i-y_i}{n-k} \\
 & = \frac{0.862}{4-3} \\
 & = 0.862 \\
E[(\hat{\beta} - \beta)(\hat{\beta} - \beta)'] & = \hat{\sigma^2}(X'X)^(-1) \\
 & = 0.863 \left(\begin{array}{ccc}
0.860 & 0.241 & -0.638 \\
0.241 & 0.702 & -0.397 \\
-0.638 & -0.397 & -0.702 \end{array}\right) \\
 & = \left(\begin{matrix}
0.742 & 0.208 & -0.551 \\
0.208 & 0.606 & -0.342 \\
-0.551 & -0.342 & 0.606 \end{matrix}\right) \\
SE(\hat{\beta}) & = \left(\begin{array}{c} \sqrt{0.742} \\ \sqrt{0.606} \\ \sqrt{0.606} \end{array}\right) \\
 & = \left(\begin{array}{c}0.861 \\ 0.778 \\ 0.778 \end{array}\right)
\end{split}
\end{equation}
$$
This test was passed; see `LmOLS_Test.cpp:31-34`.

The coefficient of determination of the model is given by $R^2 = 1 - \frac{SSR}{SST}$. Given our data, the coefficient of determination is:
$$
\begin{equation}
\begin{split}
R^2 & = 1 - \frac{SSR}{SST} \\
 & = 1 - \frac{0.863}{1.828} \\
 & = 0.528
\end{split}
\end{equation}
$$
This test was passed; see `LmOLS_Test.cpp:36`.

## Validation against R Statistics Package and Existing Regression Analysis Results

Henderson and Velleman (1981) present exemplars of regression analyses with two different datasets; one dataset, extracted from the 1974 _Motor Trend_ magazine, has become a canonical dataset within statistics packages for teaching and algorithm validation purposes. This data, which compresses fuel consumption and 10 different aspects of automotive design for 32 cars, was used by the original authors to illustrate their model building procedure in examining the relationship between gasoline mileage in gallons per 100 miles (GPM), car weight in thousands of pounds (WT), and horsepower (HP). Henderson and Velleman settled on the following model:
$$
GPM = \beta_0 + \beta_{WT}WT + \beta_{HP/WT}HP/WT + \epsilon
$$
where $\epsilon \sim N(0,\sigma^2)$. This dataset has been included within the basic distribution of the R statistical programming software as `mtcars`.

We will test our implementation of the OLS estimator in the following way: First, we will prepare a design matrix containing both $WT$ and $HP/WT$ variables, alongside a $GPM$ vector in formats that are legible to C++. Using these data, both our implementation and R will produce estimates of $\beta$, in addition to a coefficient of determination. The R implementation of statistical procedures in the base package `stats` has been audited for use in regulated clinical trial environments, where it was found that it provided reliable parameter estimates for generalized linear models (The R Foundation for Statistical Computing, 2018). We will compare the output of our C++ implementation of OLS against the output of R in addition to the estimates provided in Henderson and Velleman (1981) to check for correspondence.

```{r}
test_df <- mtcars %>%
        transmute(
                GPG = (1/mpg)*100, #  Gallons per Mile = (Miles per Gallon)^-1, 
                WT = wt,
                HP_WT = hp / wt
        )

head(test_df)

r_mod <- lm(GPG ~ WT + HP_WT, data = test_df)
```
The estimates, SEs of the coefficients, and the coefficient of determination for this model are identical between the C++ implementation (see `LmOLS_Test.cpp:105-123`), the R implementation of linear model fitting, and the original paper. 